{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9ILC73dI9G9"
   },
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "is8dFihPJRmW"
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:06:10.086730Z",
     "start_time": "2021-12-14T17:06:07.550274Z"
    },
    "executionInfo": {
     "elapsed": 1256,
     "status": "ok",
     "timestamp": 1639339325481,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "OYR89FOfI37J"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.5.3'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Fast AI (PyTorch wrapper)\n",
    "from fastai import *\n",
    "from fastai.vision.all import *\n",
    "import fastai\n",
    "fastai.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:06:10.097680Z",
     "start_time": "2021-12-14T17:06:10.093130Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1639339325484,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "PW9VU5jIJOeK"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:06:10.108509Z",
     "start_time": "2021-12-14T17:06:10.099962Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1639339325484,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "EAFb1zouJO0h",
    "outputId": "4224118a-ac2f-4080-a8f1-190b7df4f375"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tesla V100-SXM2-16GB'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure GPU is being used \n",
    "torch.cuda.current_device() \n",
    "torch.cuda.device(0)\n",
    "torch.cuda.get_device_name(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:06:10.155690Z",
     "start_time": "2021-12-14T17:06:10.115913Z"
    }
   },
   "outputs": [],
   "source": [
    "# Notebook auto reloads code. (Ref: http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jn0LWLskJToR"
   },
   "source": [
    "## Import Created Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:06:10.198157Z",
     "start_time": "2021-12-14T17:06:10.162121Z"
    },
    "id": "A9Df0-4YJV1H"
   },
   "outputs": [],
   "source": [
    "from quantization_functions import quant_aware_resnet_model\n",
    "from quantization_functions import post_training_quant_model\n",
    "from quantization_functions import train_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AMMfGCwTLWsq"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:06:10.240409Z",
     "start_time": "2021-12-14T17:06:10.204949Z"
    },
    "id": "b4-R5xIcLmdt"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "TEST_BATCH_SIZE = 16\n",
    "N_CLASS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:06:10.282054Z",
     "start_time": "2021-12-14T17:06:10.247356Z"
    }
   },
   "outputs": [],
   "source": [
    "# Download Imagenette 320 pixel\n",
    "\n",
    "path = untar_data(URLs.IMAGENETTE_320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:06:10.327126Z",
     "start_time": "2021-12-14T17:06:10.289042Z"
    }
   },
   "outputs": [],
   "source": [
    "imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(112),\n",
    "    transforms.RandomHorizontalFlip(), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*imagenet_stats,inplace=True)\n",
    "])\n",
    "\n",
    "test_tfms = transforms.Compose([\n",
    "    transforms.Resize(128),\n",
    "    transforms.CenterCrop(112),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(*imagenet_stats)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:06:10.436302Z",
     "start_time": "2021-12-14T17:06:10.335423Z"
    }
   },
   "outputs": [],
   "source": [
    "# PyTorch datasets\n",
    "\n",
    "trainset = datasets.ImageFolder(path/\"train\", train_tfms)\n",
    "testset = datasets.ImageFolder(path/\"val\", test_tfms)\n",
    "\n",
    "# PyTorch data loaders\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(testset, batch_size=TEST_BATCH_SIZE, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z378KmkPI8n2"
   },
   "source": [
    "# Resnet 50 Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:06:12.616413Z",
     "start_time": "2021-12-14T17:06:12.592700Z"
    },
    "id": "EM6H0tupNLeT"
   },
   "outputs": [],
   "source": [
    "N_EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:06:12.821459Z",
     "start_time": "2021-12-14T17:06:12.794921Z"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_DIR = 'checkpoint/imagenette_resnet50'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XxyL_hxTNL6j"
   },
   "source": [
    "## Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T15:31:28.157249Z",
     "start_time": "2021-12-14T15:31:25.867748Z"
    },
    "id": "Wfw_BQo0fhPF"
   },
   "outputs": [],
   "source": [
    "base_model = torchvision.models.resnet50(pretrained=True)\n",
    "base_model.fc = nn.Linear(base_model.fc.in_features, N_CLASS) # Change top layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T15:39:30.393888Z",
     "start_time": "2021-12-14T15:31:29.368424Z"
    },
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "_fFaNnSSNXwv",
    "outputId": "afc949b1-8e19-4233-cc01-2074798aa750"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train - epoch:  0: : 74it [01:08,  1.08it/s, loss=0.48]                       \n",
      "val - epoch:  0: : 123it [00:16,  7.67it/s, val_loss=0.148, train_loss=0.48, acc=0.95]                        \n",
      "train - epoch:  1: : 74it [00:29,  2.49it/s, loss=0.21]                       \n",
      "val - epoch:  1: : 123it [00:13,  9.30it/s, val_loss=0.126, train_loss=0.21, acc=0.96]                        \n",
      "train - epoch:  2: : 74it [00:29,  2.50it/s, loss=0.203]                      \n",
      "val - epoch:  2: : 123it [00:13,  8.93it/s, val_loss=0.13, train_loss=0.203, acc=0.959]                        \n",
      "train - epoch:  3: : 74it [00:29,  2.55it/s, loss=0.171]                      \n",
      "val - epoch:  3: : 123it [00:13,  9.32it/s, val_loss=0.14, train_loss=0.171, acc=0.957]                        \n",
      "train - epoch:  4: : 74it [00:29,  2.54it/s, loss=0.173]                      \n",
      "val - epoch:  4: : 123it [00:13,  9.25it/s, val_loss=0.133, train_loss=0.173, acc=0.961]                       \n",
      "train - epoch:  5: : 74it [00:30,  2.46it/s, loss=0.15]                       \n",
      "val - epoch:  5: : 123it [00:13,  9.16it/s, val_loss=0.128, train_loss=0.15, acc=0.961]                       \n",
      "train - epoch:  6: : 74it [00:28,  2.58it/s, loss=0.158]                      \n",
      "val - epoch:  6: : 123it [00:12,  9.60it/s, val_loss=0.132, train_loss=0.158, acc=0.958]                       \n",
      "train - epoch:  7: : 74it [00:28,  2.60it/s, loss=0.144]                      \n",
      "val - epoch:  7: : 123it [00:12,  9.61it/s, val_loss=0.14, train_loss=0.144, acc=0.956]                        \n",
      "train - epoch:  8: : 74it [00:28,  2.56it/s, loss=0.137]                      \n",
      "val - epoch:  8: : 123it [00:13,  9.32it/s, val_loss=0.132, train_loss=0.137, acc=0.957]                       \n",
      "train - epoch:  9: : 74it [00:30,  2.46it/s, loss=0.13]                       \n",
      "val - epoch:  9: : 123it [00:13,  9.02it/s, val_loss=0.137, train_loss=0.13, acc=0.955]                       \n"
     ]
    }
   ],
   "source": [
    "### Train Loop\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(base_model.parameters(), 1e-2, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "train_loop.train_model(\n",
    "    train_dl=train_loader, \n",
    "    val_dl=test_loader, \n",
    "    model=base_model, \n",
    "    optimizer=optimizer, \n",
    "    criterion=criterion,\n",
    "    clip_value=1e-2,\n",
    "    epochs=N_EPOCH, save=f\"{SAVE_DIR}/base_model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T15:56:32.556680Z",
     "start_time": "2021-12-14T15:56:18.192704Z"
    },
    "colab": {
     "background_save": true
    },
    "id": "aJyLHCM8bBFH",
    "outputId": "a99eb48f-4de7-4dbd-9fda-3a610e181b24"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 123/123 [00:13<00:00,  8.90it/s, acc=0.96] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9602547770700637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "base_model = torchvision.models.resnet50(pretrained=False)\n",
    "base_model.fc = nn.Linear(base_model.fc.in_features, N_CLASS) # Change top layer\n",
    "\n",
    "base_model.load_state_dict(torch.load(f'{SAVE_DIR}/base_model/model_weights.pt'))\n",
    "\n",
    "# Validation accuracy\n",
    "train_loop.test_model(test_loader, base_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8y6NZlHQYZH"
   },
   "source": [
    "## Post Training Quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frTh5sWvmCXA"
   },
   "source": [
    "### 8 bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:00:53.203810Z",
     "start_time": "2021-12-14T16:00:50.312942Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1639008821078,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "GL29AUmrR3Vf",
    "outputId": "edc37568-38c8-45df-94b2-88d16b092703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remained state dict odict_keys([])\n"
     ]
    }
   ],
   "source": [
    "# Convert base model to a custom quantization layer with the trained weights\n",
    "c_base_model = quant_aware_resnet_model.CResnet50(num_class=10, q_num_bit=8, qat=False,\n",
    "                                                  pretrained=f'{SAVE_DIR}/base_model/model_weights.pt')\n",
    "c_base_model.quantize(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:01:14.235514Z",
     "start_time": "2021-12-14T16:00:53.206674Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 109704,
     "status": "ok",
     "timestamp": 1639008945820,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "piIpEik6S1kR",
    "outputId": "a3441a92-e8a4-4dee-f98a-a7362d7495eb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:20<00:00, 11.73it/s, acc=0.821]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8214012738853503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Forward pass to have quantized weights\n",
    "train_loop.test_model(test_loader, c_base_model) # use test_loader to avoid out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:01:21.700671Z",
     "start_time": "2021-12-14T16:01:21.625434Z"
    },
    "id": "aoISQcR-PuoY"
   },
   "outputs": [],
   "source": [
    "# Convert to quantized model\n",
    "q_base_model = post_training_quant_model.QResnet50(num_class=10)\n",
    "q_base_model.convert_from(c_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:01:41.673377Z",
     "start_time": "2021-12-14T16:01:23.901224Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6937,
     "status": "ok",
     "timestamp": 1639008967545,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "K1vVMgjqQbUF",
    "outputId": "0b625bf7-9840-4e65-bef6-315fa33cca8e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:17<00:00, 13.87it/s, acc=0.809]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8089171974522293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "train_loop.test_model(test_loader, q_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:01:42.977178Z",
     "start_time": "2021-12-14T16:01:42.886408Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{SAVE_DIR}/ptq8bit_model_weights.pt', 'wb') as f:\n",
    "    torch.save(q_base_model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:02:26.402892Z",
     "start_time": "2021-12-14T16:02:23.594943Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remained state dict odict_keys([])\n"
     ]
    }
   ],
   "source": [
    "# Convert base model to a custom quantization layer with the trained weights\n",
    "c_base_model = quant_aware_resnet_model.CResnet50(num_class=10, q_num_bit=7, qat=False,\n",
    "                                                  pretrained=f'{SAVE_DIR}/base_model/model_weights.pt')\n",
    "c_base_model.quantize(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:02:47.191219Z",
     "start_time": "2021-12-14T16:02:26.405441Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:20<00:00, 11.87it/s, acc=0.821]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8214012738853503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Forward pass to have quantized weights\n",
    "train_loop.test_model(test_loader, c_base_model) # use test_loader to avoid out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:02:48.951673Z",
     "start_time": "2021-12-14T16:02:48.876545Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to quantized model\n",
    "q_base_model = post_training_quant_model.QResnet50(num_class=10)\n",
    "q_base_model.convert_from(c_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:03:06.994250Z",
     "start_time": "2021-12-14T16:02:49.484286Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:17<00:00, 14.08it/s, acc=0.791]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7910828025477707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "train_loop.test_model(test_loader, q_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:03:07.643182Z",
     "start_time": "2021-12-14T16:03:07.552209Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{SAVE_DIR}/ptq7bit_model_weights.pt', 'wb') as f:\n",
    "    torch.save(q_base_model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:03:24.712685Z",
     "start_time": "2021-12-14T16:03:21.874706Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remained state dict odict_keys([])\n"
     ]
    }
   ],
   "source": [
    "# Convert base model to a custom quantization layer with the trained weights\n",
    "c_base_model = quant_aware_resnet_model.CResnet50(num_class=10, q_num_bit=6, qat=False,\n",
    "                                                  pretrained=f'{SAVE_DIR}/base_model/model_weights.pt')\n",
    "c_base_model.quantize(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:03:45.855795Z",
     "start_time": "2021-12-14T16:03:24.717043Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:21<00:00, 11.67it/s, acc=0.821]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8214012738853503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Forward pass to have quantized weights\n",
    "train_loop.test_model(test_loader, c_base_model) # use test_loader to avoid out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:03:45.933457Z",
     "start_time": "2021-12-14T16:03:45.857903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to quantized model\n",
    "q_base_model = post_training_quant_model.QResnet50(num_class=10)\n",
    "q_base_model.convert_from(c_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:04:03.332668Z",
     "start_time": "2021-12-14T16:03:45.935910Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:17<00:00, 14.17it/s, acc=0.755]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.7554140127388536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "train_loop.test_model(test_loader, q_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:04:03.428869Z",
     "start_time": "2021-12-14T16:04:03.336555Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{SAVE_DIR}/ptq6bit_model_weights.pt', 'wb') as f:\n",
    "    torch.save(q_base_model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:04:38.301227Z",
     "start_time": "2021-12-14T16:04:35.492586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remained state dict odict_keys([])\n"
     ]
    }
   ],
   "source": [
    "# Convert base model to a custom quantization layer with the trained weights\n",
    "c_base_model = quant_aware_resnet_model.CResnet50(num_class=10, q_num_bit=5, qat=False,\n",
    "                                                  pretrained=f'{SAVE_DIR}/base_model/model_weights.pt')\n",
    "c_base_model.quantize(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:04:59.595024Z",
     "start_time": "2021-12-14T16:04:38.303499Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:21<00:00, 11.58it/s, acc=0.821]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8214012738853503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Forward pass to have quantized weights\n",
    "train_loop.test_model(test_loader, c_base_model) # use test_loader to avoid out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:04:59.675484Z",
     "start_time": "2021-12-14T16:04:59.598102Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to quantized model\n",
    "q_base_model = post_training_quant_model.QResnet50(num_class=10)\n",
    "q_base_model.convert_from(c_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:05:16.656254Z",
     "start_time": "2021-12-14T16:04:59.677669Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:16<00:00, 14.52it/s, acc=0.365]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.3653503184713376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "train_loop.test_model(test_loader, q_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:05:16.742288Z",
     "start_time": "2021-12-14T16:05:16.658752Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{SAVE_DIR}/ptq5bit_model_weights.pt', 'wb') as f:\n",
    "    torch.save(q_base_model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:05:35.235227Z",
     "start_time": "2021-12-14T16:05:32.456595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remained state dict odict_keys([])\n"
     ]
    }
   ],
   "source": [
    "# Convert base model to a custom quantization layer with the trained weights\n",
    "c_base_model = quant_aware_resnet_model.CResnet50(num_class=10, q_num_bit=4, qat=False,\n",
    "                                                  pretrained=f'{SAVE_DIR}/base_model/model_weights.pt')\n",
    "c_base_model.quantize(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:05:55.787863Z",
     "start_time": "2021-12-14T16:05:35.237403Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:20<00:00, 12.00it/s, acc=0.821]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8214012738853503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Forward pass to have quantized weights\n",
    "train_loop.test_model(test_loader, c_base_model) # use test_loader to avoid out of memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:05:55.870055Z",
     "start_time": "2021-12-14T16:05:55.791585Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to quantized model\n",
    "q_base_model = post_training_quant_model.QResnet50(num_class=10)\n",
    "q_base_model.convert_from(c_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:06:13.190867Z",
     "start_time": "2021-12-14T16:05:55.872520Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:17<00:00, 14.23it/s, acc=0.0721] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.07210191082802547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "train_loop.test_model(test_loader, q_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:06:13.278435Z",
     "start_time": "2021-12-14T16:06:13.194068Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{SAVE_DIR}/ptq4bit_model_weights.pt', 'wb') as f:\n",
    "    torch.save(q_base_model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mmpG9_9PO8E5"
   },
   "source": [
    "## Quantization Aware Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4PRbWTsmmRhL"
   },
   "source": [
    "### 8-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:06:35.231296Z",
     "start_time": "2021-12-14T16:06:33.310655Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 872,
     "status": "ok",
     "timestamp": 1639008986864,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "oB6gK6MUO98Z",
    "outputId": "41b3ce18-cba3-4bee-e1f0-8c79f4e48292",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remained state dict odict_keys(['fc.weight', 'fc.bias'])\n"
     ]
    }
   ],
   "source": [
    "# Create model with custom quantization layer from the start\n",
    "c_base_model = quant_aware_resnet_model.CResnet50(num_class=10, q_num_bit=8, qat=True, pretrained=True)\n",
    "c_base_model.quantize(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:16:06.153640Z",
     "start_time": "2021-12-14T16:06:36.367203Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 331716,
     "status": "ok",
     "timestamp": 1639009319891,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "QJFoGEjZNTkA",
    "outputId": "9973e40d-0a42-499a-d085-8f2746212eef"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train - epoch:  0: : 74it [00:34,  2.15it/s, loss=0.688]                      \n",
      "val - epoch:  0: : 246it [00:23, 10.45it/s, val_loss=0.275, train_loss=0.688, acc=0.916]                       \n",
      "train - epoch:  1: : 74it [00:33,  2.21it/s, loss=0.304]                      \n",
      "val - epoch:  1: : 246it [00:22, 11.07it/s, val_loss=0.236, train_loss=0.304, acc=0.926]                       \n",
      "train - epoch:  2: : 74it [00:33,  2.24it/s, loss=0.267]                      \n",
      "val - epoch:  2: : 246it [00:23, 10.57it/s, val_loss=0.19, train_loss=0.267, acc=0.942]                        \n",
      "train - epoch:  3: : 74it [00:33,  2.18it/s, loss=0.252]                      \n",
      "val - epoch:  3: : 246it [00:21, 11.23it/s, val_loss=0.202, train_loss=0.252, acc=0.94]                        \n",
      "train - epoch:  4: : 74it [00:33,  2.20it/s, loss=0.239]                      \n",
      "val - epoch:  4: : 246it [00:22, 10.87it/s, val_loss=0.193, train_loss=0.239, acc=0.943]                       \n",
      "train - epoch:  5: : 74it [00:32,  2.24it/s, loss=0.23]                       \n",
      "val - epoch:  5: : 246it [00:23, 10.52it/s, val_loss=0.187, train_loss=0.23, acc=0.942]                       \n",
      "train - epoch:  6: : 74it [00:34,  2.15it/s, loss=0.223]                      \n",
      "val - epoch:  6: : 246it [00:22, 10.94it/s, val_loss=0.178, train_loss=0.223, acc=0.945]                       \n",
      "train - epoch:  7: : 74it [00:33,  2.19it/s, loss=0.201]                      \n",
      "val - epoch:  7: : 246it [00:21, 11.29it/s, val_loss=0.16, train_loss=0.201, acc=0.952]                        \n",
      "train - epoch:  8: : 74it [00:33,  2.22it/s, loss=0.196]                      \n",
      "val - epoch:  8: : 246it [00:22, 11.13it/s, val_loss=0.16, train_loss=0.196, acc=0.953]                        \n",
      "train - epoch:  9: : 74it [00:33,  2.23it/s, loss=0.186]                      \n",
      "val - epoch:  9: : 246it [00:21, 11.20it/s, val_loss=0.155, train_loss=0.186, acc=0.952]                       \n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(c_base_model.parameters(), 1e-3, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "train_loop.train_model(\n",
    "    train_dl=train_loader, \n",
    "    val_dl=test_loader, \n",
    "    model=c_base_model, \n",
    "    optimizer=optimizer, \n",
    "    criterion=criterion,\n",
    "    clip_value=1e-2,\n",
    "    epochs=N_EPOCH, save=f\"{SAVE_DIR}/qat8bit\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:16:49.836975Z",
     "start_time": "2021-12-14T16:16:49.772300Z"
    },
    "id": "muNQF34RWwZ6"
   },
   "outputs": [],
   "source": [
    "# Convert to quantized model\n",
    "q_base_model = post_training_quant_model.QResnet50(num_class=10)\n",
    "q_base_model.convert_from(c_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:17:08.567723Z",
     "start_time": "2021-12-14T16:16:51.014504Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6681,
     "status": "ok",
     "timestamp": 1639009326731,
     "user": {
      "displayName": "Rifqi Luthfan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64",
      "userId": "07442021322718158104"
     },
     "user_tz": 300
    },
    "id": "UPl1MlvHJHOY",
    "outputId": "8fd185d3-fcd2-4124-e81e-ec5f23efad93"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:17<00:00, 14.04it/s, acc=0.951]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.9513375796178344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "train_loop.test_model(test_loader, q_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:20:13.462030Z",
     "start_time": "2021-12-14T16:20:13.361002Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{SAVE_DIR}/qat8bit/model_weights_quantized.pt', 'wb') as f:\n",
    "    torch.save(q_base_model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:20:32.713560Z",
     "start_time": "2021-12-14T16:20:31.955426Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remained state dict odict_keys(['fc.weight', 'fc.bias'])\n"
     ]
    }
   ],
   "source": [
    "# Create model with custom quantization layer from the start\n",
    "c_base_model = quant_aware_resnet_model.CResnet50(num_class=10, q_num_bit=7, qat=True, pretrained=True)\n",
    "c_base_model.quantize(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:29:52.887325Z",
     "start_time": "2021-12-14T16:20:32.716003Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train - epoch:  0: : 74it [00:34,  2.17it/s, loss=0.875]                      \n",
      "val - epoch:  0: : 246it [00:22, 10.72it/s, val_loss=0.326, train_loss=0.875, acc=0.897]                       \n",
      "train - epoch:  1: : 74it [00:33,  2.21it/s, loss=0.364]                      \n",
      "val - epoch:  1: : 246it [00:22, 11.07it/s, val_loss=0.249, train_loss=0.364, acc=0.925]                       \n",
      "train - epoch:  2: : 74it [00:33,  2.19it/s, loss=0.311]                      \n",
      "val - epoch:  2: : 246it [00:21, 11.29it/s, val_loss=0.248, train_loss=0.311, acc=0.92]                        \n",
      "train - epoch:  3: : 74it [00:32,  2.27it/s, loss=0.289]                      \n",
      "val - epoch:  3: : 246it [00:22, 11.07it/s, val_loss=0.203, train_loss=0.289, acc=0.941]                       \n",
      "train - epoch:  4: : 74it [00:33,  2.23it/s, loss=0.262]                      \n",
      "val - epoch:  4: : 246it [00:21, 11.50it/s, val_loss=0.193, train_loss=0.262, acc=0.94]                        \n",
      "train - epoch:  5: : 74it [00:33,  2.22it/s, loss=0.241]                      \n",
      "val - epoch:  5: : 246it [00:21, 11.33it/s, val_loss=0.187, train_loss=0.241, acc=0.94]                        \n",
      "train - epoch:  6: : 74it [00:32,  2.29it/s, loss=0.24]                       \n",
      "val - epoch:  6: : 246it [00:21, 11.26it/s, val_loss=0.179, train_loss=0.24, acc=0.943]                       \n",
      "train - epoch:  7: : 74it [00:33,  2.20it/s, loss=0.231]                      \n",
      "val - epoch:  7: : 246it [00:21, 11.32it/s, val_loss=0.161, train_loss=0.231, acc=0.95]                        \n",
      "train - epoch:  8: : 74it [00:32,  2.25it/s, loss=0.221]                      \n",
      "val - epoch:  8: : 246it [00:21, 11.20it/s, val_loss=0.174, train_loss=0.221, acc=0.945]                       \n",
      "train - epoch:  9: : 74it [00:32,  2.26it/s, loss=0.214]                      \n",
      "val - epoch:  9: : 246it [00:21, 11.40it/s, val_loss=0.178, train_loss=0.214, acc=0.948]                       \n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(c_base_model.parameters(), 1e-3, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "train_loop.train_model(\n",
    "    train_dl=train_loader, \n",
    "    val_dl=test_loader, \n",
    "    model=c_base_model, \n",
    "    optimizer=optimizer, \n",
    "    criterion=criterion,\n",
    "    clip_value=1e-2,\n",
    "    epochs=N_EPOCH, save=f\"{SAVE_DIR}/qat7bit\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:29:52.960763Z",
     "start_time": "2021-12-14T16:29:52.890108Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to quantized model\n",
    "q_base_model = post_training_quant_model.QResnet50(num_class=10)\n",
    "q_base_model.convert_from(c_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:30:11.134162Z",
     "start_time": "2021-12-14T16:29:52.964420Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:18<00:00, 13.57it/s, acc=0.944]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.944203821656051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "train_loop.test_model(test_loader, q_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:30:11.220755Z",
     "start_time": "2021-12-14T16:30:11.136726Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{SAVE_DIR}/qat7bit/model_weights_quantized.pt', 'wb') as f:\n",
    "    torch.save(q_base_model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:30:43.154273Z",
     "start_time": "2021-12-14T16:30:42.399408Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remained state dict odict_keys(['fc.weight', 'fc.bias'])\n"
     ]
    }
   ],
   "source": [
    "# Create model with custom quantization layer from the start\n",
    "c_base_model = quant_aware_resnet_model.CResnet50(num_class=10, q_num_bit=6, qat=True, pretrained=True)\n",
    "c_base_model.quantize(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:39:58.422752Z",
     "start_time": "2021-12-14T16:30:43.156649Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train - epoch:  0: : 74it [00:33,  2.19it/s, loss=1.19]                      \n",
      "val - epoch:  0: : 246it [00:22, 10.95it/s, val_loss=0.532, train_loss=1.19, acc=0.831]                       \n",
      "train - epoch:  1: : 74it [00:32,  2.25it/s, loss=0.705]                      \n",
      "val - epoch:  1: : 246it [00:21, 11.24it/s, val_loss=0.46, train_loss=0.705, acc=0.86]                         \n",
      "train - epoch:  2: : 74it [00:33,  2.22it/s, loss=0.638]                      \n",
      "val - epoch:  2: : 246it [00:22, 10.95it/s, val_loss=0.43, train_loss=0.638, acc=0.863]                        \n",
      "train - epoch:  3: : 74it [00:32,  2.28it/s, loss=0.571]                      \n",
      "val - epoch:  3: : 246it [00:21, 11.59it/s, val_loss=0.37, train_loss=0.571, acc=0.879]                        \n",
      "train - epoch:  4: : 74it [00:32,  2.25it/s, loss=0.526]                      \n",
      "val - epoch:  4: : 246it [00:22, 11.04it/s, val_loss=0.426, train_loss=0.526, acc=0.849]                       \n",
      "train - epoch:  5: : 74it [00:32,  2.30it/s, loss=0.515]                      \n",
      "val - epoch:  5: : 246it [00:21, 11.38it/s, val_loss=0.355, train_loss=0.515, acc=0.891]                       \n",
      "train - epoch:  6: : 74it [00:31,  2.36it/s, loss=0.489]                      \n",
      "val - epoch:  6: : 246it [00:20, 11.80it/s, val_loss=0.371, train_loss=0.489, acc=0.868]                       \n",
      "train - epoch:  7: : 74it [00:32,  2.27it/s, loss=0.482]                      \n",
      "val - epoch:  7: : 246it [00:21, 11.21it/s, val_loss=0.349, train_loss=0.482, acc=0.878]                       \n",
      "train - epoch:  8: : 74it [00:33,  2.21it/s, loss=0.466]                      \n",
      "val - epoch:  8: : 246it [00:21, 11.40it/s, val_loss=0.372, train_loss=0.466, acc=0.875]                       \n",
      "train - epoch:  9: : 74it [00:33,  2.20it/s, loss=0.455]                      \n",
      "val - epoch:  9: : 246it [00:22, 11.11it/s, val_loss=0.346, train_loss=0.455, acc=0.897]                       \n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(c_base_model.parameters(), 1e-2, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "train_loop.train_model(\n",
    "    train_dl=train_loader, \n",
    "    val_dl=test_loader, \n",
    "    model=c_base_model, \n",
    "    optimizer=optimizer, \n",
    "    criterion=criterion,\n",
    "    clip_value=1e-2,\n",
    "    epochs=N_EPOCH, save=f\"{SAVE_DIR}/qat6bit\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:39:58.488389Z",
     "start_time": "2021-12-14T16:39:58.424718Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to quantized model\n",
    "q_base_model = post_training_quant_model.QResnet50(num_class=10)\n",
    "q_base_model.convert_from(c_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:40:15.979574Z",
     "start_time": "2021-12-14T16:39:58.491391Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:17<00:00, 14.16it/s, acc=0.843]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.8433121019108281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "train_loop.test_model(test_loader, q_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:40:16.069524Z",
     "start_time": "2021-12-14T16:40:15.982098Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{SAVE_DIR}/qat6bit/model_weights_quantized.pt', 'wb') as f:\n",
    "    torch.save(q_base_model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:40:47.075015Z",
     "start_time": "2021-12-14T16:40:46.348509Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remained state dict odict_keys(['fc.weight', 'fc.bias'])\n"
     ]
    }
   ],
   "source": [
    "# Create model with custom quantization layer from the start\n",
    "c_base_model = quant_aware_resnet_model.CResnet50(num_class=10, q_num_bit=5, qat=True, pretrained=True)\n",
    "c_base_model.quantize(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:50:01.962033Z",
     "start_time": "2021-12-14T16:40:47.077502Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train - epoch:  0: : 74it [00:32,  2.24it/s, loss=2.14]                      \n",
      "val - epoch:  0: : 246it [00:21, 11.29it/s, val_loss=1.78, train_loss=2.14, acc=0.377]                       \n",
      "train - epoch:  1: : 74it [00:32,  2.26it/s, loss=1.72]                      \n",
      "val - epoch:  1: : 246it [00:21, 11.65it/s, val_loss=1.5, train_loss=1.72, acc=0.472]                        \n",
      "train - epoch:  2: : 74it [00:32,  2.28it/s, loss=1.58]                      \n",
      "val - epoch:  2: : 246it [00:21, 11.30it/s, val_loss=1.46, train_loss=1.58, acc=0.489]                       \n",
      "train - epoch:  3: : 74it [00:32,  2.27it/s, loss=1.48]                      \n",
      "val - epoch:  3: : 246it [00:21, 11.37it/s, val_loss=1.3, train_loss=1.48, acc=0.554]                        \n",
      "train - epoch:  4: : 74it [00:32,  2.29it/s, loss=1.39]                      \n",
      "val - epoch:  4: : 246it [00:22, 10.96it/s, val_loss=1.24, train_loss=1.39, acc=0.576]                       \n",
      "train - epoch:  5: : 74it [00:32,  2.25it/s, loss=1.34]                      \n",
      "val - epoch:  5: : 246it [00:21, 11.55it/s, val_loss=1.21, train_loss=1.34, acc=0.574]                       \n",
      "train - epoch:  6: : 74it [00:33,  2.22it/s, loss=1.4]                       \n",
      "val - epoch:  6: : 246it [00:22, 11.09it/s, val_loss=1.41, train_loss=1.4, acc=0.502]                       \n",
      "train - epoch:  7: : 74it [00:33,  2.24it/s, loss=1.47]                      \n",
      "val - epoch:  7: : 246it [00:22, 11.15it/s, val_loss=1.33, train_loss=1.47, acc=0.547]                       \n",
      "train - epoch:  8: : 74it [00:33,  2.23it/s, loss=1.51]                      \n",
      "val - epoch:  8: : 246it [00:22, 11.12it/s, val_loss=1.41, train_loss=1.51, acc=0.529]                       \n",
      "train - epoch:  9: : 74it [00:33,  2.21it/s, loss=1.42]                      \n",
      "val - epoch:  9: : 246it [00:21, 11.24it/s, val_loss=1.24, train_loss=1.42, acc=0.591]                       \n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(c_base_model.parameters(), 1e-3, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "train_loop.train_model(\n",
    "    train_dl=train_loader, \n",
    "    val_dl=test_loader, \n",
    "    model=c_base_model, \n",
    "    optimizer=optimizer, \n",
    "    criterion=criterion,\n",
    "    clip_value=1e-2,\n",
    "    epochs=N_EPOCH, save=f\"{SAVE_DIR}/qat5bit\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:50:02.031533Z",
     "start_time": "2021-12-14T16:50:01.964793Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to quantized model\n",
    "q_base_model = post_training_quant_model.QResnet50(num_class=10)\n",
    "q_base_model.convert_from(c_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:50:19.118077Z",
     "start_time": "2021-12-14T16:50:02.033383Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:17<00:00, 14.43it/s, acc=0.444]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.4438216560509554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "train_loop.test_model(test_loader, q_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T16:50:19.205824Z",
     "start_time": "2021-12-14T16:50:19.120571Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{SAVE_DIR}/qat5bit/model_weights_quantized.pt', 'wb') as f:\n",
    "    torch.save(q_base_model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-bit quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:06:16.198265Z",
     "start_time": "2021-12-14T17:06:15.430388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remained state dict odict_keys(['fc.weight', 'fc.bias'])\n"
     ]
    }
   ],
   "source": [
    "# Create model with custom quantization layer from the start\n",
    "c_base_model = quant_aware_resnet_model.CResnet50(num_class=10, q_num_bit=4, qat=True, pretrained=True)\n",
    "c_base_model.quantize(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:15:32.764762Z",
     "start_time": "2021-12-14T17:06:16.200691Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train - epoch:  0: : 74it [00:34,  2.16it/s, loss=4.13]                      \n",
      "val - epoch:  0: : 246it [00:21, 11.32it/s, val_loss=3.16, train_loss=4.13, acc=0.124]                       \n",
      "train - epoch:  1: : 74it [00:32,  2.27it/s, loss=3]                         \n",
      "val - epoch:  1: : 246it [00:21, 11.38it/s, val_loss=2.85, train_loss=3, acc=0.135]                       \n",
      "train - epoch:  2: : 74it [00:32,  2.30it/s, loss=2.78]                      \n",
      "val - epoch:  2: : 246it [00:21, 11.38it/s, val_loss=2.73, train_loss=2.78, acc=0.134]                       \n",
      "train - epoch:  3: : 74it [00:32,  2.26it/s, loss=2.69]                      \n",
      "val - epoch:  3: : 246it [00:21, 11.33it/s, val_loss=2.62, train_loss=2.69, acc=0.141]                       \n",
      "val - epoch:  5: : 246it [00:21, 11.38it/s, val_loss=2.31, train_loss=2.34, acc=0.0991]                       \n",
      "train - epoch:  6: : 74it [00:34,  2.16it/s, loss=2.51]                      \n",
      "val - epoch:  6: : 246it [00:22, 11.11it/s, val_loss=2.94, train_loss=2.51, acc=0.13]                        \n",
      "train - epoch:  7: : 74it [00:32,  2.25it/s, loss=2.71]                      \n",
      "val - epoch:  7: : 246it [00:22, 11.14it/s, val_loss=2.55, train_loss=2.71, acc=0.124]                       \n",
      "train - epoch:  8: : 74it [00:32,  2.25it/s, loss=2.47]                      \n",
      "val - epoch:  8: : 246it [00:21, 11.62it/s, val_loss=2.41, train_loss=2.47, acc=0.14]                        \n",
      "train - epoch:  9: : 74it [00:33,  2.18it/s, loss=2.42]                      \n",
      "val - epoch:  9: : 246it [00:21, 11.53it/s, val_loss=2.39, train_loss=2.42, acc=0.138]                       \n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(c_base_model.parameters(), 1e-3, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "train_loop.train_model(\n",
    "    train_dl=train_loader, \n",
    "    val_dl=test_loader, \n",
    "    model=c_base_model, \n",
    "    optimizer=optimizer, \n",
    "    criterion=criterion,\n",
    "    clip_value=1e-2,\n",
    "    epochs=N_EPOCH, save=f\"{SAVE_DIR}/qat4bit\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:15:32.835283Z",
     "start_time": "2021-12-14T17:15:32.767488Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert to quantized model\n",
    "q_base_model = post_training_quant_model.QResnet50(num_class=10)\n",
    "q_base_model.convert_from(c_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:15:49.682072Z",
     "start_time": "2021-12-14T17:15:32.837419Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 246/246 [00:16<00:00, 14.63it/s, acc=0.113]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.11286624203821656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Validation accuracy\n",
    "train_loop.test_model(test_loader, q_base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-14T17:15:49.853976Z",
     "start_time": "2021-12-14T17:15:49.684347Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(f'{SAVE_DIR}/qat4bit/model_weights_quantized.pt', 'wb') as f:\n",
    "    torch.save(q_base_model.state_dict(), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyOh2T6Tj/G/RPl19+iwVusG",
   "collapsed_sections": [],
   "name": "CIFAR10.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
