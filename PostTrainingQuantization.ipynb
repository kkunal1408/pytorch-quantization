{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PostTrainingQuantization.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyMjFFyRkNAmdhZ1aJKQhCC3"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"70ba146e52b8401a8449e8d854805375":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_8a31768eaa2744118d500156dd19d4f3","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_58f506dca12943c8968499a5ab4d2ad2","IPY_MODEL_698059eb9fd1480998a2dd412c0edb5b","IPY_MODEL_7f73fa4fde4b4d519d1a57c8e6658ed4"]}},"8a31768eaa2744118d500156dd19d4f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"58f506dca12943c8968499a5ab4d2ad2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_765fd263c5f24f9d8a76620249dc8f65","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b71213da2c7c4e3f93c3fde60f7e367b"}},"698059eb9fd1480998a2dd412c0edb5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_165fd651c8854ca6b20f72e75b45c8e8","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":46830571,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":46830571,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_448f514f8bfc43beb5504e20ec8ea70c"}},"7f73fa4fde4b4d519d1a57c8e6658ed4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_fb0b0bcb25d54ac39e49b255491c5e1b","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 44.7M/44.7M [00:00&lt;00:00, 108MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_91f5b588c19849328542c371e5f749c3"}},"765fd263c5f24f9d8a76620249dc8f65":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"b71213da2c7c4e3f93c3fde60f7e367b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"165fd651c8854ca6b20f72e75b45c8e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"448f514f8bfc43beb5504e20ec8ea70c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb0b0bcb25d54ac39e49b255491c5e1b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"91f5b588c19849328542c371e5f749c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","source":["# Initialization"],"metadata":{"id":"Rvz00bqxYRBe"}},{"cell_type":"markdown","source":["## Import Libraries"],"metadata":{"id":"MN9JpV9gYT_j"}},{"cell_type":"code","source":["from __future__ import print_function\n","import argparse\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import torchvision\n","from torchvision import datasets, transforms"],"metadata":{"id":"gkPvXMMVYSmn","executionInfo":{"status":"ok","timestamp":1638982743458,"user_tz":300,"elapsed":6393,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["from collections import namedtuple"],"metadata":{"id":"27vDLu7TdtGY","executionInfo":{"status":"ok","timestamp":1638982743458,"user_tz":300,"elapsed":15,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# make sure GPU is being used \n","torch.cuda.current_device() \n","torch.cuda.device(0)\n","torch.cuda.get_device_name(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"A5rQM860du9Q","executionInfo":{"status":"ok","timestamp":1638982743459,"user_tz":300,"elapsed":13,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"1b067981-bb1d-4fac-dd11-9e67f5be6a89"},"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'Tesla K80'"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","source":["# Model"],"metadata":{"id":"1LNPZimgYV5A"}},{"cell_type":"code","source":["model = torchvision.models.resnet18(pretrained=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87,"referenced_widgets":["70ba146e52b8401a8449e8d854805375","8a31768eaa2744118d500156dd19d4f3","58f506dca12943c8968499a5ab4d2ad2","698059eb9fd1480998a2dd412c0edb5b","7f73fa4fde4b4d519d1a57c8e6658ed4","765fd263c5f24f9d8a76620249dc8f65","b71213da2c7c4e3f93c3fde60f7e367b","165fd651c8854ca6b20f72e75b45c8e8","448f514f8bfc43beb5504e20ec8ea70c","fb0b0bcb25d54ac39e49b255491c5e1b","91f5b588c19849328542c371e5f749c3"]},"id":"Ea7S9IYb-9bj","executionInfo":{"status":"ok","timestamp":1638983041822,"user_tz":300,"elapsed":889,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"68a2dc10-bbac-4018-f8d8-60df8fa98e45"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"]},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"70ba146e52b8401a8449e8d854805375","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0.00/44.7M [00:00<?, ?B/s]"]},"metadata":{}}]},{"cell_type":"code","source":["model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MvoVExI0_ESs","executionInfo":{"status":"ok","timestamp":1638983042197,"user_tz":300,"elapsed":4,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"a599686c-0225-4ef7-821a-c4e8fc07bac2"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ResNet(\n","  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n","  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (relu): ReLU(inplace=True)\n","  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n","  (layer1): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer2): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer3): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (layer4): Sequential(\n","    (0): BasicBlock(\n","      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (downsample): Sequential(\n","        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      )\n","    )\n","    (1): BasicBlock(\n","      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","      (relu): ReLU(inplace=True)\n","      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    )\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n","  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",")"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":[""],"metadata":{"id":"7sITE-mk_FpH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## CIFAR-10"],"metadata":{"id":"kQrZgBK4d-aF"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8AXlIRwrX9xP"},"outputs":[],"source":["class Net(nn.Module):\n","    def __init__(self):\n","      \n","        super(Net, self).__init__()\n","        num_channels = 3\n","          \n","        self.conv1 = nn.Conv2d(num_channels, 20, 5, 1)\n","        self.conv2 = nn.Conv2d(20, 50, 5, 1)\n","        self.fc1 = nn.Linear(1250, 500)\n","        self.flatten_shape = 1250\n","\n","        self.fc2 = nn.Linear(500, 10)\n","        \n","      \n","    def forward(self, x, vis=False, axs=None):\n","        X = 0\n","        Y = 0\n","\n","        if vis:\n","            axs[X,Y].set_xlabel('Entry into network, input distribution visualised below: ')\n","            visualise(x, axs[X,Y])\n","            \n","            axs[X,Y+1].set_xlabel(\"Visualising weights of conv 1 layer: \")\n","            visualise(self.conv1.weight.data, axs[X,Y+1])\n","\n","\n","        x = F.relu(self.conv1(x))\n","\n","        if vis:\n","            axs[X,Y+2].set_xlabel('Output after conv1 visualised below: ')\n","            visualise(x,axs[X,Y+2])\n","            \n","            axs[X,Y+3].set_xlabel(\"Visualising weights of conv 2 layer: \")\n","            visualise(self.conv2.weight.data, axs[X,Y+3])\n","\n","        x = F.max_pool2d(x, 2, 2)\n","        x = F.relu(self.conv2(x))\n","\n","        if vis:\n","            axs[X,Y+4].set_xlabel('Output after conv2 visualised below: ')\n","            visualise(x,axs[X,Y+4])\n","            \n","            axs[X+1,Y].set_xlabel(\"Visualising weights of fc 1 layer: \")\n","            visualise(self.fc1.weight.data, axs[X+1,Y])\n","\n","        x = F.max_pool2d(x, 2, 2)  \n","        x = x.view(-1, self.flatten_shape)\n","        x = F.relu(self.fc1(x))\n","\n","        if vis:\n","            axs[X+1,Y+1].set_xlabel('Output after fc1 visualised below: ')\n","            visualise(x,axs[X+1,Y+1])\n","            \n","            axs[X+1,Y+2].set_xlabel(\"Visualising weights of fc 2 layer: \")\n","            visualise(self.fc2.weight.data, axs[X+1,Y+2])\n","\n","        x = self.fc2(x)\n","\n","        if vis:\n","            axs[X+1,Y+3].set_xlabel('Output after fc2 visualised below: ')\n","            visualise(x,axs[X+1,Y+3])\n","\n","        return F.log_softmax(x, dim=1)\n","    "]},{"cell_type":"code","source":[""],"metadata":{"id":"exFTaRZqeN6z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Post Training Quantization"],"metadata":{"id":"DKbjTC2rYWV7"}},{"cell_type":"markdown","source":["## Train Test Loop Functions"],"metadata":{"id":"QvdPmc2KeT9M"}},{"cell_type":"code","source":["def test(args, model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))"],"metadata":{"id":"FW8YzvXSd08g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train(args, model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        \n","   \n","        if batch_idx % args[\"log_interval\"] == 0:\n","            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))"],"metadata":{"id":"_HTiEx_veRrO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def main():\n"," \n","    batch_size = 64\n","    test_batch_size = 64\n","    epochs = 10\n","    lr = 0.01\n","    momentum = 0.5\n","    seed = 1\n","    log_interval = 500\n","    save_model = False\n","    no_cuda = False\n","    \n","    use_cuda = not no_cuda and torch.cuda.is_available()\n","\n","    torch.manual_seed(seed)\n","\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","\n","    transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","    \n","    trainset = datasets.CIFAR10(root='./dataCifar', train=True,\n","                                            download=True, transform=transform)\n","    train_loader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n","                                            shuffle=True, num_workers=2)\n","    \n","    testset = datasets.CIFAR10(root='./dataCifar', train=False,\n","                                        download=True, transform=transform)\n","    \n","    test_loader = torch.utils.data.DataLoader(testset, batch_size=test_batch_size,\n","                                            shuffle=False, num_workers=2)\n","          \n","  \n","    model = Net().to(device)\n","    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n","    args = {}\n","    args[\"log_interval\"] = log_interval\n","    for epoch in range(1, epochs + 1):\n","        train(args, model, device, train_loader, optimizer, epoch)\n","        test(args, model, device, test_loader)\n","\n","    if (save_model):\n","        torch.save(model.state_dict(),\"mnist_cnn.pt\")\n","    \n","    return model"],"metadata":{"id":"N4eIzA6feXyo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = main()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_tDFjOId0mb","executionInfo":{"status":"ok","timestamp":1638974506761,"user_tz":300,"elapsed":208387,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"51119510-3d06-41e6-f429-3c0ed53ce1d7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n","Files already downloaded and verified\n","Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.293677\n","Train Epoch: 1 [32000/50000 (64%)]\tLoss: 1.767184\n","\n","Test set: Average loss: 1.6384, Accuracy: 4033/10000 (40%)\n","\n","Train Epoch: 2 [0/50000 (0%)]\tLoss: 1.780285\n","Train Epoch: 2 [32000/50000 (64%)]\tLoss: 1.297291\n","\n","Test set: Average loss: 1.4415, Accuracy: 4781/10000 (48%)\n","\n","Train Epoch: 3 [0/50000 (0%)]\tLoss: 1.177380\n","Train Epoch: 3 [32000/50000 (64%)]\tLoss: 1.102388\n","\n","Test set: Average loss: 1.3010, Accuracy: 5353/10000 (54%)\n","\n","Train Epoch: 4 [0/50000 (0%)]\tLoss: 1.143748\n","Train Epoch: 4 [32000/50000 (64%)]\tLoss: 1.148048\n","\n","Test set: Average loss: 1.2959, Accuracy: 5309/10000 (53%)\n","\n","Train Epoch: 5 [0/50000 (0%)]\tLoss: 1.405380\n","Train Epoch: 5 [32000/50000 (64%)]\tLoss: 1.081317\n","\n","Test set: Average loss: 1.1161, Accuracy: 6033/10000 (60%)\n","\n","Train Epoch: 6 [0/50000 (0%)]\tLoss: 1.020266\n","Train Epoch: 6 [32000/50000 (64%)]\tLoss: 0.954466\n","\n","Test set: Average loss: 1.0464, Accuracy: 6352/10000 (64%)\n","\n","Train Epoch: 7 [0/50000 (0%)]\tLoss: 0.843963\n","Train Epoch: 7 [32000/50000 (64%)]\tLoss: 0.929612\n","\n","Test set: Average loss: 1.0252, Accuracy: 6426/10000 (64%)\n","\n","Train Epoch: 8 [0/50000 (0%)]\tLoss: 1.092845\n","Train Epoch: 8 [32000/50000 (64%)]\tLoss: 0.893130\n","\n","Test set: Average loss: 1.0219, Accuracy: 6465/10000 (65%)\n","\n","Train Epoch: 9 [0/50000 (0%)]\tLoss: 0.728850\n","Train Epoch: 9 [32000/50000 (64%)]\tLoss: 0.877861\n","\n","Test set: Average loss: 0.9444, Accuracy: 6775/10000 (68%)\n","\n","Train Epoch: 10 [0/50000 (0%)]\tLoss: 0.725154\n","Train Epoch: 10 [32000/50000 (64%)]\tLoss: 0.789281\n","\n","Test set: Average loss: 0.9150, Accuracy: 6840/10000 (68%)\n","\n"]}]},{"cell_type":"markdown","source":["## Quantisation of Network"],"metadata":{"id":"kr5Mh5lTfXUi"}},{"cell_type":"markdown","source":["### Quantization Functions"],"metadata":{"id":"Gsush1Aef8wH"}},{"cell_type":"code","source":["QTensor = namedtuple('QTensor', ['tensor', 'scale', 'zero_point'])"],"metadata":{"id":"kn6cEusZeo_j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calcScaleZeroPoint(min_val, max_val,num_bits):\n","    # Calc Scale and zero point of next\n","    qmin = 0.\n","    qmax = 2.**num_bits - 1.\n","    \n","    scale_next = (max_val - min_val) / (qmax - qmin)\n","    initial_zero_point = qmin - min_val / scale_next\n","  \n","    if initial_zero_point < qmin:\n","        zero_point_next = qmin\n","    elif initial_zero_point > qmax:\n","        zero_point_next = qmax\n","    else:\n","        zero_point_next = initial_zero_point\n","        #print(zero_point_next)\n","        \n","    zero_point_next = int(zero_point_next)\n","    \n","    return scale_next, zero_point_next"],"metadata":{"id":"NaFa3g7ZfaON"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def quantize_tensor(x, num_bits, min_val=None, max_val=None):\n","    \n","    #x = torch.nan_to_num(x)\n","    if not min_val and not max_val:\n","        min_val, max_val = x.min(), x.max()\n","    else:\n","        x.clamp_(min_val, max_val)\n","\n","    qmin = 0.\n","    qmax = 2.**num_bits - 1.\n","\n","    scale, zero_point = calcScaleZeroPoint(min_val, max_val, num_bits)\n","    x = zero_point + x / scale\n","    x.clamp_(qmin, qmax).round_()\n","    \n","    return QTensor(tensor=x, scale=scale, zero_point=zero_point)"],"metadata":{"id":"qPfWsKBzfcFg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dequantize_tensor(q_x):\n","    return q_x.scale * (q_x.tensor.float() - q_x.zero_point)"],"metadata":{"id":"REdzXhqSfg-t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def calcScaleZeroPointSym(min_val, max_val,num_bits):\n","  \n","    # Calc Scale\n","    max_val = max(abs(min_val), abs(max_val))\n","    qmax = 2.**(num_bits-1) - 1.\n","    \n","    scale = max_val / qmax\n","    \n","    return scale, 0"],"metadata":{"id":"YUrPTO-xfhbS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def quantize_tensor_sym(x, num_bits, min_val=None, max_val=None):\n","    #x = torch.nan_to_num(x)\n","    if not min_val and not max_val:\n","        min_val, max_val = x.min(), x.max()\n","    else:\n","        x.clamp_(min_val, max_val)\n","        max_val = max(abs(min_val), abs(max_val))\n","    \n","    qmax = 2.**(num_bits-1) - 1.\n","\n","    scale = max_val / qmax   \n","\n","    x = x/scale\n","\n","    x.clamp_(-qmax, qmax).round_()\n","    return QTensor(tensor=x, scale=scale, zero_point=0)"],"metadata":{"id":"gVKtvjVDfi4F"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def dequantize_tensor_sym(q_x):\n","    return q_x.scale * (q_x.tensor.float())"],"metadata":{"id":"M8q7iWq2fkBk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Rework Forward pass of Linear and Conv Layers to support Quantisation"],"metadata":{"id":"S2l5cPEDgA0A"}},{"cell_type":"code","source":["def quantizeLayer(x, layer, stat, scale_x, zp_x, vis=False, axs=None, X=None, Y=None, sym=False, num_bits=8):\n","    # for both conv and linear layers\n","    \n","    # cache old values\n","    W = layer.weight.data\n","    B = layer.bias.data\n","    \n","    # WEIGHTS SIMULATED QUANTISED\n","    \n","    # quantise weights, activations are already quantised\n","    if sym:\n","        w = quantize_tensor_sym(layer.weight.data,num_bits=num_bits)\n","        b = quantize_tensor_sym(layer.bias.data,num_bits=num_bits)\n","    else:\n","        w = quantize_tensor(layer.weight.data, num_bits=num_bits)\n","        b = quantize_tensor(layer.bias.data, num_bits=num_bits)\n","        \n","    layer.weight.data = w.tensor.float()\n","    layer.bias.data = b.tensor.float()\n","    \n","    ## END WEIGHTS QUANTISED SIMULATION\n","    \n","    if vis:\n","        axs[X,Y].set_xlabel(\"Visualising weights of layer: \")\n","        visualise(layer.weight.data, axs[X,Y])\n","        \n","    # QUANTISED OP, USES SCALE AND ZERO POINT TO DO LAYER FORWARD PASS. (How does backprop change here ?)\n","    # This is Quantisation Arithmetic\n","    \n","    scale_w = w.scale\n","    zp_w = w.zero_point\n","    scale_b = b.scale\n","    zp_b = b.zero_point\n","    \n","    if sym:\n","        scale_next, zero_point_next = calcScaleZeroPointSym(min_val=stat['min'], max_val=stat['max'], num_bits=num_bits)\n","    else:\n","        scale_next, zero_point_next = calcScaleZeroPoint(min_val=stat['min'], max_val=stat['max'], num_bits=num_bits)\n","        \n","    # Preparing input by saturating range to num_bits range.\n","    if sym:\n","        x_ = x.float()\n","        layer.weight.data = ((scale_x * scale_w) / scale_next)*(layer.weight.data)\n","        layer.bias.data = (scale_b/scale_next)*(layer.bias.data)\n","    else:\n","        x_ = x.float() - zp_x\n","        layer.weight.data = ((scale_x * scale_w) / scale_next)*(layer.weight.data - zp_w)\n","        layer.bias.data = (scale_b/scale_next)*(layer.bias.data + zp_b)\n","\n","    # All (Fake) int computation\n","    if sym:  \n","        x = (layer(x_)) \n","        qmin = -2.**(num_bits -1)\n","        qmax = 2.**(num_bits -1) - 1\n","    else:\n","        x = (layer(x_)) + zero_point_next\n","        qmin = 0\n","        qmax = 2.**(num_bits) - 1\n","        \n","    # cast to int\n","    x.clamp_(qmin, qmax).round_()\n","    \n","    # Perform relu too\n","    x = F.leaky_relu(x) #?\n","    #x = F.relu(x)\n","    \n","    # Reset weights for next forward pass\n","    layer.weight.data = W\n","    layer.bias.data = B\n","    \n","    return x, scale_next, zero_point_next"],"metadata":{"id":"SPZvdnlQfle7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Get Stats for Quantising Activations of Network.\n","\n","This is done by running the network with around 1000 examples and getting the average min and max activation values before and after each layer."],"metadata":{"id":"mOI37_6ngNkp"}},{"cell_type":"code","source":["# Get Min and max of x tensor, and stores it\n","def updateStats(x, stats, key):\n","    max_val, _ = torch.max(x, dim=1)\n","    min_val, _ = torch.min(x, dim=1)\n","    \n","    # add ema calculation\n","    \n","    if key not in stats:\n","        stats[key] = {\"max\": torch.max(max_val).item(), \"min\": torch.min(min_val).item(), \"total\": 1}\n","        \n","    else:\n","        stats[key]['max'] = max(stats[key]['max'],torch.max(max_val).item())\n","        stats[key]['min'] = min(stats[key]['min'],torch.min(max_val).item())\n","        stats[key]['total'] += 1\n","        \n","    weighting = 2.0 / (stats[key]['total']) + 1\n","    \n","    if 'ema_min' in stats[key]:\n","        stats[key]['ema_min'] = weighting*(min_val.mean().item()) + (1- weighting) * stats[key]['ema_min']\n","    else:\n","        stats[key]['ema_min'] = weighting*(min_val.mean().item())\n","        \n","    if 'ema_max' in stats[key]:\n","        stats[key]['ema_max'] = weighting*(max_val.mean().item()) + (1- weighting) * stats[key]['ema_max']\n","    else:\n","        stats[key]['ema_max'] = weighting*(max_val.mean().item())\n","    \n","    \n","    return stats"],"metadata":{"id":"QIbpF5DpgOXH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reworked Forward Pass to access activation Stats through updateStats function\n","def gatherActivationStats(model, x, stats):\n","    \n","    stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv1')\n","    \n","    x = F.relu(model.conv1(x))\n","    \n","    x = F.max_pool2d(x, 2, 2)\n","    \n","    stats = updateStats(x.clone().view(x.shape[0], -1), stats, 'conv2')\n","    \n","    x = F.relu(model.conv2(x))\n","    \n","    x = F.max_pool2d(x, 2, 2)\n","    \n","    x = x.view(-1, 1250)\n","    \n","    stats = updateStats(x, stats, 'fc1')\n","    \n","    x = F.relu(model.fc1(x))\n","    \n","    stats = updateStats(x, stats, 'fc2')\n","    \n","    x = model.fc2(x)\n","    \n","    stats = updateStats(x, stats, 'out')\n","\n","    return stats"],"metadata":{"id":"1FnQpsCbgQPO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Entry function to get stats of all functions.\n","def gatherStats(model, test_loader):\n","    device = 'cuda'    \n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    stats = {}\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            stats = gatherActivationStats(model, data, stats)\n","    \n","    final_stats = {}\n","    for key, value in stats.items():\n","        final_stats[key] = { \"max\" : value[\"max\"], \"min\" : value[\"min\"], \"ema_min\": value[\"ema_min\"], \"ema_max\": value[\"ema_max\"] }\n","    return final_stats"],"metadata":{"id":"2216VSaugRoc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Forward Pass for Quantised Inference"],"metadata":{"id":"Tiii3XN8geeS"}},{"cell_type":"code","source":["def quantForward(model, x, stats, vis=False, axs=None, sym=False, num_bits=8):\n","    X = 0\n","    Y = 0\n","    # Quantise before inputting into incoming layers\n","    if sym:\n","        x = quantize_tensor_sym(x, min_val=stats['conv1']['min'], max_val=stats['conv1']['max'], num_bits=num_bits)\n","    else:\n","        x = quantize_tensor(x, min_val=stats['conv1']['min'], max_val=stats['conv1']['max'], num_bits=num_bits)\n","\n","    if vis:\n","        axs[X,Y].set_xlabel('Entry into network, input distribution visualised below: ')\n","        visualise(x.tensor, axs[X,Y])\n","        \n","    x, scale_next, zero_point_next = quantizeLayer(x.tensor, model.conv1, stats['conv2'], x.scale, x.zero_point, vis, axs, X=X, Y=Y+1, sym=sym, num_bits=num_bits)\n","\n","    x = F.max_pool2d(x, 2, 2)\n","  \n","    if vis:\n","        axs[X,Y+2].set_xlabel('Output after conv1 visualised below: ')\n","        visualise(x,axs[X,Y+2])\n","\n","    x, scale_next, zero_point_next = quantizeLayer(x, model.conv2, stats['fc1'], scale_next, zero_point_next, vis, axs, X=X, Y=Y+3, sym=sym, num_bits=num_bits)\n","\n","    x = F.max_pool2d(x, 2, 2)\n","\n","    if vis:\n","        axs[X,Y+4].set_xlabel('Output after conv2 visualised below: ')\n","        visualise(x,axs[X,Y+4])\n","\n","    x = x.view(-1, 1250)\n","\n","    x, scale_next, zero_point_next = quantizeLayer(x, model.fc1, stats['fc2'], scale_next, zero_point_next, vis, axs, X=X+1, Y=0, sym=sym, num_bits=num_bits)\n","\n","    if vis:\n","        axs[X+1,Y+1].set_xlabel('Output after fc1 visualised below: ')\n","        visualise(x,axs[X+1,Y+1])\n","  \n","    x, scale_next, zero_point_next = quantizeLayer(x, model.fc2, stats['out'], scale_next, zero_point_next, vis, axs, X=X+1, Y=Y+2, sym=sym, num_bits=num_bits)\n","    \n","    if vis:\n","        axs[X+1,Y+3].set_xlabel('Output after fc2 visualised below: ')\n","        visualise(x,axs[X+1,Y+3])\n","        \n","    # Back to dequant for final layer\n","    if sym:\n","        x = dequantize_tensor_sym(QTensor(tensor=x, scale=scale_next, zero_point=zero_point_next))\n","    else:\n","        x = dequantize_tensor(QTensor(tensor=x, scale=scale_next, zero_point=zero_point_next))\n","\n","    if vis:\n","        axs[X+1,Y+4].set_xlabel('Output after fc2 but dequantised visualised below: ')\n","        visualise(x,axs[X+1,Y+4])\n","\n","    return F.log_softmax(x, dim=1)"],"metadata":{"id":"Cl_0_jChgb1N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def testQuant(model, test_loader, quant=False, stats=None, sym=False, num_bits=8):\n","    device = 'cuda'\n","    \n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            if quant:\n","                output = quantForward(model, data, stats, sym=sym, num_bits=num_bits)\n","            else:\n","                output = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))"],"metadata":{"id":"VNXuyDX9ghpm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Get Accuracy for Quantized Model"],"metadata":{"id":"RLvUU5ajglTy"}},{"cell_type":"code","source":["import copy\n","q_model = copy.deepcopy(model)"],"metadata":{"id":"Uh63fJ5Sgqs-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["kwargs = {'num_workers': 1, 'pin_memory': True}\n","\n","transform = transforms.Compose(\n","        [transforms.ToTensor(),\n","        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","testset = datasets.CIFAR10(root='./dataCifar', train=False,\n","                                        download=True, transform=transform)\n","    \n","test_loader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True, **kwargs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UhCeZKFegrKY","executionInfo":{"status":"ok","timestamp":1638974931623,"user_tz":300,"elapsed":884,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"23a1b2c4-8c03-4d77-8c69-c715fc961c7a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Files already downloaded and verified\n"]}]},{"cell_type":"code","source":["# Non Quantized\n","testQuant(q_model, test_loader, quant=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aQbqiXOphL5I","executionInfo":{"status":"ok","timestamp":1638974944957,"user_tz":300,"elapsed":3812,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"56d7acd7-a380-4924-d5d2-bd0248fff341"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 0.9150, Accuracy: 6840/10000 (68%)\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"cgSGy7jLhbbw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Gather Stats of Activations"],"metadata":{"id":"Y_S69xjohcXS"}},{"cell_type":"code","source":["stats = gatherStats(q_model, test_loader)\n","print(stats)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0aMkWynDhe-M","executionInfo":{"status":"ok","timestamp":1638975062004,"user_tz":300,"elapsed":3987,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"eafc3a2b-a02e-46ef-e0b4-d120114c958f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'conv1': {'max': 1.0, 'min': -1.0, 'ema_min': -0.8961577837067178, 'ema_max': 0.906515912253188}, 'conv2': {'max': 10.053322792053223, 'min': 0.0, 'ema_min': 0.0, 'ema_max': 4.797752144011583}, 'fc1': {'max': 13.948284149169922, 'min': 0.0, 'ema_min': 0.0, 'ema_max': 5.490657327288742}, 'fc2': {'max': 8.615355491638184, 'min': 0.0, 'ema_min': 0.0, 'ema_max': 3.403652658938573}, 'out': {'max': 16.977933883666992, 'min': -8.503494262695312, 'ema_min': -4.213035598256015, 'ema_max': 5.073444108768709}}\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"djcKl6l9hg0I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["testQuant(q_model, test_loader, quant=True, stats=stats, sym=False, num_bits=8)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wuvGa6MUhRHY","executionInfo":{"status":"ok","timestamp":1638975100178,"user_tz":300,"elapsed":4428,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"94dd8bf5-6eb8-4883-adcc-81227a84d2db"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 3.6772, Accuracy: 4785/10000 (48%)\n","\n"]}]},{"cell_type":"code","source":["testQuant(q_model, test_loader, quant=True, stats=stats, sym=False, num_bits=4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cw6rG5Z9hudV","executionInfo":{"status":"ok","timestamp":1638975113827,"user_tz":300,"elapsed":4435,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"3d658edd-c043-49a0-cacc-4ef0697a6ee4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 4.4507, Accuracy: 4093/10000 (41%)\n","\n"]}]},{"cell_type":"code","source":["testQuant(q_model, test_loader, quant=True, stats=stats, sym=False, num_bits=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Xxdnoc7Ch3hW","executionInfo":{"status":"ok","timestamp":1638975121084,"user_tz":300,"elapsed":4434,"user":{"displayName":"Rifqi Luthfan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi6REDrzyVNDZl2VT9M3BzwlBYF_1Y_KHDREx_t=s64","userId":"07442021322718158104"}},"outputId":"283f4f12-94e1-4412-e1e3-3f36f13c5a20"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test set: Average loss: 10.1600, Accuracy: 1746/10000 (17%)\n","\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"-ynxUzmyhOcl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"yr4IgtR0gjft"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"WQ9tpNcGgJYl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"fbRqabAheoaY"},"execution_count":null,"outputs":[]}]}